{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5262b0-9118-41df-a6c6-a4fa003f59ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import torch\n",
    "from torchtext import data\n",
    "import re\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "# alt.data_transformers.enable('data_server')\n",
    "# from sklearn.preprocessing import MinMaxScaler, StandardScaler, OrdinalEncoder, OneHotEncoder\n",
    "# from sklearn.pipeline import Pipeline, make_pipeline\n",
    "# from sklearn.model_selection import train_test_split, cross_val_score, cross_validate\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.dummy import DummyClassifier\n",
    "# from sklearn.utils import resample\n",
    "# from sklearn.metrics import roc_curve\n",
    "# from sklearn.metrics import auc\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.pipeline import Pipeline as imbpipeline\n",
    "# from sklearn.metrics import f1_score as f1\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import torch\n",
    "# from torch import nn\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# from torch.utils.data import TensorDataset\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39dd1e",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6240ae5-43f9-45af-978d-9678856795ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               Text  Target\n",
       "0  Positive  im getting on borderlands and i will murder yo...       1\n",
       "1  Positive  I am coming to the borders and I will kill you...       1\n",
       "2  Positive  im getting on borderlands and i will kill you ...       1\n",
       "3  Positive  im coming on borderlands and i will murder you...       1\n",
       "4  Positive  im getting on borderlands 2 and i will murder ...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"twitter_training.csv\", header = None)\n",
    "df = df.drop([0, 1], axis = 1)\n",
    "df = df.applymap(str)\n",
    "df.columns = [\"Sentiment\", \"Text\"]\n",
    "df[\"Target\"] = df[\"Sentiment\"].map({\"Negative\" : 0, \"Positive\" : 1, \"Neutral\" : 2, \"Irrelevant\" : 3})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa1a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_eng = stopwords.words('english')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    link_re_pattern = \"https?:\\/\\/t.co/[\\w]+\"\n",
    "    punct = \"[^\\w\\s]+\"\n",
    "    text = re.sub(link_re_pattern, \"\", text)\n",
    "    text = re.sub(punct, \"\", text)\n",
    "    return text.lower()\n",
    "\n",
    "def build_tweet_corpus(data):\n",
    "\n",
    "    word_counter = build_tweet_counter(data)\n",
    "    ls = []\n",
    "    for key in word_counter:\n",
    "        if word_counter[key] < 5:\n",
    "            ls.append(key)\n",
    "    \n",
    "    stopwords = set(stopwords_eng + ls)\n",
    "    tweet_corpus = set()\n",
    "    for x in data:\n",
    "        for word in x:\n",
    "            if word not in stopwords:\n",
    "                tweet_corpus.add(word)\n",
    "    return list(tweet_corpus)\n",
    "\n",
    "def build_tweet_counter(data):\n",
    "    \n",
    "    tweet_corpus = []\n",
    "    for x in data:\n",
    "        for word in x:\n",
    "            if word not in stopwords_eng:\n",
    "                tweet_corpus.append(word)\n",
    "    return Counter(tweet_corpus)\n",
    "\n",
    "\n",
    "def process_data(df):\n",
    "\n",
    "    tokenizer = TweetTokenizer()\n",
    "\n",
    "    df[\"Text\"] = df[\"Text\"].apply(preprocess_text)\n",
    "    df[\"Tokens\"] = df[\"Text\"].apply(tokenizer.tokenize)\n",
    "    df[\"Tokens\"] = df[\"Tokens\"].apply(lambda x: [word for word in x if word not in stopwords_eng])\n",
    "\n",
    "    return df\n",
    "\n",
    "def tokenize(df, tweet_corpus, max_len):\n",
    "    corpus_dict = corpora.Dictionary([tweet_corpus]).token2id\n",
    "    \n",
    "    def to_tokenids(text):\n",
    "        tokens = [corpus_dict[x] for x in text if x in corpus_dict]\n",
    "        if len(tokens) <= 1:\n",
    "            return \"NA\"\n",
    "        else:\n",
    "            return np.array(tokens)\n",
    "\n",
    "    df[\"Tokens\"] = df[\"Tokens\"].apply(to_tokenids)\n",
    "    df = df[df[\"Tokens\"] != \"NA\"]\n",
    "    lens = torch.LongTensor([len(x) for x in df[\"Tokens\"]])\n",
    "\n",
    "    def pad(x):\n",
    "        if len(x) < max_len:\n",
    "            x = np.append(x, [0]*(max_len - len(x)))\n",
    "        return x[0:max_len]\n",
    "\n",
    "    df['Tokens'] = df[\"Tokens\"].apply(pad)\n",
    "    return df, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a32714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = process_data(df)\n",
    "traindata, valdata = train_test_split(df, test_size = 0.2, random_state= 321)\n",
    "\n",
    "# length = df_processed[\"Tokens\"].apply(len)\n",
    "# plt.hist(length, bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b23e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andy8\\anaconda3\\envs\\stock_trade\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\andy8\\AppData\\Local\\Temp\\ipykernel_23836\\3237871160.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tokens'] = df[\"Tokens\"].apply(pad)\n"
     ]
    }
   ],
   "source": [
    "df_processed = process_data(df)\n",
    "traindata, valdata = train_test_split(df, test_size = 0.2, random_state= 321)\n",
    "\n",
    "train_corpus = build_tweet_corpus(df[\"Tokens\"])\n",
    "\n",
    "max_len = 35\n",
    "traindata, trainlens = tokenize(traindata, train_corpus, 35)\n",
    "valdata, vallens = tokenize(valdata, train_corpus, 35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f06d7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.stack(traindata[\"Tokens\"])\n",
    "trainY = np.array(traindata[\"Target\"])\n",
    "validX = np.stack(valdata[\"Tokens\"])\n",
    "validY = np.array(valdata[\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "217170a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchtrain = TensorDataset(torch.from_numpy(trainX).to(torch.int64), torch.from_numpy(trainY).to(torch.int64))\n",
    "torchtval = TensorDataset(torch.from_numpy(validX).to(torch.int64), torch.from_numpy(validY).to(torch.int64))\n",
    "\n",
    "trainloader = DataLoader(torchtrain, shuffle=True, batch_size=16)\n",
    "validloader = DataLoader(torchtval, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56939a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 35])\n",
      "torch.Size([16, 35, 32])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.LSTM(16, 20, 2)\n",
    "\n",
    "vocab_size = len(train_corpus)\n",
    "embedding_dim = 32\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "inputs, labels = next(dataiter)\n",
    "print(inputs.shape)\n",
    "labels = labels.to(torch.int64)\n",
    "lengths = 35 - (inputs == 0).sum(dim=1)\n",
    "\n",
    "embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "# out = cnn(inputs)\n",
    "embeds = embed(inputs)\n",
    "# embeds = nn.utils.rnn.pack_padded_sequence(embeds, list(lengths), batch_first=True, enforce_sorted=False)\n",
    "print(embeds.shape)\n",
    "# print(embeds[:, None, :, :].shape)\n",
    "# embeds = embeds[:, None, :, :]\n",
    "# cnn(embeds)\n",
    "# inputs, labels = inputs.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "900d7c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN(nn.Module):\n",
    "    def __init__(self, voab_size, embedding_dim, hidden_dim, layers):\n",
    "        super(SentimentRNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(voab_size, embedding_dim)\n",
    "        self.out_dim = 1\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layers = layers\n",
    "\n",
    "        self.rnn = nn.LSTM(input_size = embedding_dim, hidden_size = hidden_dim, num_layers = layers, batch_first = True)\n",
    "    \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(hidden_dim, 4)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        lengths = 35 - (input == 0).sum(dim=1)\n",
    "        lengths.to(device)\n",
    "        hidden = self.init_hidden(batch_size)\n",
    "        embeds = self.embedding(input)\n",
    "        embeds = nn.utils.rnn.pack_padded_sequence(embeds, list(lengths), batch_first=True, enforce_sorted=False)\n",
    "        rnn_out, (h, c) = self.rnn(embeds)\n",
    "\n",
    "        # print(rnn_out)\n",
    "        # output_padded, output_lengths = pad_packed_sequence(rnn_out, batch_first=True)\n",
    "        out = self.linear(h[-1])\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        ''' Initializes hidden state '''\n",
    "        hidden = torch.zeros((self.layers, batch_size, self.hidden_dim)).to(device)\n",
    "        return hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "194639f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1169, -0.0444,  0.0165,  0.0056],\n",
      "        [-0.1142, -0.0509,  0.0188,  0.0012],\n",
      "        [-0.1176, -0.0468,  0.0155,  0.0025],\n",
      "        [-0.1117, -0.0466,  0.0168,  0.0002],\n",
      "        [-0.1131, -0.0450,  0.0163,  0.0033],\n",
      "        [-0.1111, -0.0478,  0.0177,  0.0014],\n",
      "        [-0.1106, -0.0425,  0.0151, -0.0031],\n",
      "        [-0.1169, -0.0439,  0.0142,  0.0028],\n",
      "        [-0.1074, -0.0478,  0.0213, -0.0019],\n",
      "        [-0.1036, -0.0443,  0.0205, -0.0016],\n",
      "        [-0.1113, -0.0437,  0.0169,  0.0022],\n",
      "        [-0.1152, -0.0406,  0.0195,  0.0038],\n",
      "        [-0.1107, -0.0500,  0.0208,  0.0010],\n",
      "        [-0.1082, -0.0490,  0.0192,  0.0015],\n",
      "        [-0.1146, -0.0404,  0.0148,  0.0009],\n",
      "        [-0.1122, -0.0475,  0.0162, -0.0020]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "lr=0.0001\n",
    "no_layers = 3\n",
    "vocab_size = len(train_corpus)\n",
    "embedding_dim = 32\n",
    "hidden_dim = 128\n",
    "\n",
    "model = SentimentRNN(vocab_size, embedding_dim, hidden_dim, no_layers)\n",
    "model.to(device)\n",
    "\n",
    "#moving to gpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer.step()\n",
    "\n",
    "inputs, labels = next(dataiter)\n",
    "labels = labels.to(torch.int64)\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "output = model(inputs)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "279c2c97",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.002\u001b[39m\n\u001b[0;32m      2\u001b[0m no_layers \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m----> 3\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtrain_corpus\u001b[49m)\n\u001b[0;32m      4\u001b[0m embedding_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m      5\u001b[0m hidden_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "lr=0.002\n",
    "no_layers = 2\n",
    "vocab_size = len(train_corpus)\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "\n",
    "model = SentimentRNN(vocab_size, embedding_dim, hidden_dim, no_layers)\n",
    "\n",
    "#moving to gpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# function to predict accuracy\n",
    "def acc(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c622c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "train_loss : 0.9895138439331215\n",
      "val_loss: 0.7512796044728222\n",
      "train_accuracy : 59.367778740612366\n",
      "valid accuracy: 71.67292147806005\n",
      "Validation loss decreased (inf --> 0.751280).  Saving model ...\n",
      "Epoch 2\n",
      "train_loss : 0.453000764006879\n",
      "val_loss: 0.4671245075839703\n",
      "train_accuracy : 83.94533506643559\n",
      "valid accuracy: 83.30687066974596\n",
      "Validation loss decreased (0.751280 --> 0.467125).  Saving model ...\n",
      "Epoch 3\n",
      "train_loss : 0.20630287274353504\n",
      "val_loss: 0.40945053293087946\n",
      "train_accuracy : 92.99898902368572\n",
      "valid accuracy: 86.57621247113164\n",
      "Validation loss decreased (0.467125 --> 0.409451).  Saving model ...\n",
      "Epoch 4\n",
      "train_loss : 0.11836231280037725\n",
      "val_loss: 0.42405763783332984\n",
      "train_accuracy : 95.96873194685152\n",
      "valid accuracy: 86.87211316397229\n",
      "Epoch 5\n",
      "train_loss : 0.08665485182503462\n",
      "val_loss: 0.4580252109173154\n",
      "train_accuracy : 96.98692952050838\n",
      "valid accuracy: 87.52165127020785\n",
      "Epoch 6\n",
      "train_loss : 0.07068900617182074\n",
      "val_loss: 0.4668337583155253\n",
      "train_accuracy : 97.5176920854997\n",
      "valid accuracy: 87.62990762124711\n",
      "Epoch 7\n",
      "train_loss : 0.057930099661686885\n",
      "val_loss: 0.4743706998973843\n",
      "train_accuracy : 97.95638359329867\n",
      "valid accuracy: 88.11345265588915\n",
      "Epoch 8\n",
      "train_loss : 0.05211752857549771\n",
      "val_loss: 0.4765534198359806\n",
      "train_accuracy : 98.10261409589832\n",
      "valid accuracy: 88.1784064665127\n",
      "Epoch 9\n",
      "train_loss : 0.05097875709127037\n",
      "val_loss: 0.4819372847140444\n",
      "train_accuracy : 98.19649046793761\n",
      "valid accuracy: 88.27222863741339\n",
      "Epoch 10\n",
      "train_loss : 0.04481771956391596\n",
      "val_loss: 0.48802358083937514\n",
      "train_accuracy : 98.38243789716927\n",
      "valid accuracy: 88.50317551963049\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "valid_loss_min = np.Inf\n",
    "batch_size = 16\n",
    "\n",
    "epoch_tr_loss, epoch_vl_loss = [],[]\n",
    "epoch_tr_acc, epoch_vl_acc = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = 0.0\n",
    "    corr = 0\n",
    "    tot = 0\n",
    "\n",
    "    corrval = 0\n",
    "    totval = 0\n",
    "    model.train()\n",
    "    # initialize hidden state \n",
    "    for inputs, labels in trainloader:\n",
    "        labels = labels.to(torch.int64)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "\n",
    "        output = model(inputs)\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        preds = torch.argmax(output, 1)\n",
    "        corr += (preds == labels).sum().item()\n",
    "        tot += 16\n",
    "\n",
    "    for val_inputs, val_labels in validloader:\n",
    "        val_labels = val_labels.to(torch.int64)\n",
    "        val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "\n",
    "        val_output = model(val_inputs)\n",
    "        val_loss = criterion(val_output, val_labels)\n",
    "        val_losses.append(val_loss.item())\n",
    "        # calculate the loss and perform backprop\n",
    "        val_preds = torch.argmax(val_output, 1)\n",
    "        corrval += (val_preds == val_labels).sum().item()\n",
    "        totval += 16\n",
    "\n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    print(f'train_loss : {epoch_train_loss}')\n",
    "    print(f'val_loss: {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {corr/tot*100}')\n",
    "    print(f\"valid accuracy: {corrval/totval*100}\")\n",
    "    \n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "\n",
    "    epoch_tr_acc.append(corr/tot*100)\n",
    "    epoch_vl_acc.append(corrval/totval*100)\n",
    "\n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), 'working/LSTM/state_dict.pt')\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "        valid_loss_min = epoch_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b70006be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andy8\\anaconda3\\envs\\stock_trade\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\andy8\\AppData\\Local\\Temp\\ipykernel_23836\\3237871160.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tokens'] = df[\"Tokens\"].apply(pad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuacy is: 0.9899443963027152\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.read_csv(\"twitter_validation.csv\", header = None)\n",
    "testdf = testdf.drop([0, 1], axis = 1)\n",
    "dtestdff = testdf.applymap(str)\n",
    "testdf.columns = [\"Sentiment\", \"Text\"]\n",
    "testdf[\"Target\"] = testdf[\"Sentiment\"].map({\"Negative\" : 0, \"Positive\" : 1, \"Neutral\" : 2, \"Irrelevant\" : 3})\n",
    "\n",
    "df_processed_test = process_data(testdf)\n",
    "\n",
    "max_len = 35\n",
    "testdata, testlens = tokenize(df_processed_test, train_corpus, 35)\n",
    "\n",
    "testX = np.stack(testdata[\"Tokens\"])\n",
    "testY = np.array(testdata[\"Target\"])\n",
    "torchtest = TensorDataset(torch.from_numpy(trainX).to(torch.int64), torch.from_numpy(trainY).to(torch.int64))\n",
    "\n",
    "testloader = DataLoader(torchtest, shuffle=True, batch_size=16)\n",
    "\n",
    "corrval = 0\n",
    "totval = 0\n",
    "\n",
    "for inputs, labels in testloader:\n",
    "    labels = labels.to(torch.int64)\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    output = model(inputs)\n",
    "    # calculate the loss and perform backprop\n",
    "    preds = torch.argmax(output, 1)\n",
    "    corrval += (preds == labels).sum().item()\n",
    "    totval += 16\n",
    "\n",
    "print(f\"The test accuacy is: {corrval/totval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8281f0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1efad3e53c0>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_vl_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8279553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, model, tweet_corpus, max_len):\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split(\" \")\n",
    "    corpus_dict = corpora.Dictionary([tweet_corpus]).token2id\n",
    "    tokens = [corpus_dict[x] for x in words if x in corpus_dict]\n",
    "    if len(tokens) <= 1:\n",
    "        print(\"No Valid Strings!\")\n",
    "        return None\n",
    "    else:\n",
    "        tokens = np.array(tokens)\n",
    "\n",
    "    if len(tokens) < max_len:\n",
    "        tokens = np.append(tokens, [0]*(max_len - len(tokens)))\n",
    "        tokens = tokens[0:max_len]\n",
    "    \n",
    "    tokens = torch.LongTensor(tokens[None, :])\n",
    "    tokens = tokens.to(device)\n",
    "    output = model(tokens)\n",
    "    preds = torch.argmax(output, 1)\n",
    "    return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I like cheese\", model, train_corpus, 35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1279a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
