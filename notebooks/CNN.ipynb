{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a5262b0-9118-41df-a6c6-a4fa003f59ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import torch\n",
    "from torchtext import data\n",
    "import re\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from collections import defaultdict\n",
    "from textwrap import wrap\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from gensim import corpora\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "\n",
    "# import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf39dd1e",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6240ae5-43f9-45af-978d-9678856795ad",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               Text  Target\n",
       "0  Positive  im getting on borderlands and i will murder yo...       1\n",
       "1  Positive  I am coming to the borders and I will kill you...       1\n",
       "2  Positive  im getting on borderlands and i will kill you ...       1\n",
       "3  Positive  im coming on borderlands and i will murder you...       1\n",
       "4  Positive  im getting on borderlands 2 and i will murder ...       1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"twitter_training.csv\", header = None)\n",
    "df = df.drop([0, 1], axis = 1)\n",
    "df = df.applymap(str)\n",
    "df.columns = [\"Sentiment\", \"Text\"]\n",
    "df[\"Target\"] = df[\"Sentiment\"].map({\"Negative\" : 0, \"Positive\" : 1, \"Neutral\" : 2, \"Irrelevant\" : 3})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0aa1a50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_eng = stopwords.words('english')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    link_re_pattern = \"https?:\\/\\/t.co/[\\w]+\"\n",
    "    punct = \"[^\\w\\s]+\"\n",
    "    text = re.sub(link_re_pattern, \"\", text)\n",
    "    text = re.sub(punct, \"\", text)\n",
    "    return text.lower()\n",
    "\n",
    "def build_tweet_corpus(data):\n",
    "\n",
    "    word_counter = build_tweet_counter(data)\n",
    "    ls = []\n",
    "    for key in word_counter:\n",
    "        if word_counter[key] < 5:\n",
    "            ls.append(key)\n",
    "    \n",
    "    stopwords = set(stopwords_eng + ls)\n",
    "    tweet_corpus = set()\n",
    "    for x in data:\n",
    "        for word in x:\n",
    "            if word not in stopwords:\n",
    "                tweet_corpus.add(word)\n",
    "    return list(tweet_corpus)\n",
    "\n",
    "def build_tweet_counter(data):\n",
    "    \n",
    "    tweet_corpus = []\n",
    "    for x in data:\n",
    "        for word in x:\n",
    "            if word not in stopwords_eng:\n",
    "                tweet_corpus.append(word)\n",
    "    return Counter(tweet_corpus)\n",
    "\n",
    "\n",
    "def process_data(df):\n",
    "\n",
    "    tokenizer = TweetTokenizer()\n",
    "\n",
    "    df[\"Text\"] = df[\"Text\"].apply(preprocess_text)\n",
    "    df[\"Tokens\"] = df[\"Text\"].apply(tokenizer.tokenize)\n",
    "    df[\"Tokens\"] = df[\"Tokens\"].apply(lambda x: [word for word in x if word not in stopwords_eng])\n",
    "\n",
    "    return df\n",
    "\n",
    "def tokenize(df, tweet_corpus, max_len):\n",
    "    corpus_dict = corpora.Dictionary([tweet_corpus]).token2id\n",
    "    \n",
    "    def to_tokenids(text):\n",
    "        tokens = [corpus_dict[x] for x in text if x in corpus_dict]\n",
    "        if len(tokens) <= 1:\n",
    "            return \"NA\"\n",
    "        else:\n",
    "            return np.array(tokens)\n",
    "\n",
    "    df[\"Tokens\"] = df[\"Tokens\"].apply(to_tokenids)\n",
    "    df = df[df[\"Tokens\"] != \"NA\"]\n",
    "    lens = torch.LongTensor([len(x) for x in df[\"Tokens\"]])\n",
    "\n",
    "    def pad(x):\n",
    "        if len(x) < max_len:\n",
    "            x = np.append(x, [0]*(max_len - len(x)))\n",
    "        return x[0:max_len]\n",
    "\n",
    "    df['Tokens'] = df[\"Tokens\"].apply(pad)\n",
    "    return df, lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14a32714",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = process_data(df)\n",
    "traindata, valdata = train_test_split(df, test_size = 0.2, random_state= 321)\n",
    "\n",
    "# length = df_processed[\"Tokens\"].apply(len)\n",
    "# plt.hist(length, bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19b23e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andy8\\anaconda3\\envs\\stock_trade\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\andy8\\AppData\\Local\\Temp\\ipykernel_9008\\3237871160.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tokens'] = df[\"Tokens\"].apply(pad)\n"
     ]
    }
   ],
   "source": [
    "df_processed = process_data(df)\n",
    "traindata, valdata = train_test_split(df, test_size = 0.2, random_state= 321)\n",
    "\n",
    "train_corpus = build_tweet_corpus(df[\"Tokens\"])\n",
    "\n",
    "max_len = 35\n",
    "traindata, trainlens = tokenize(traindata, train_corpus, 35)\n",
    "valdata, vallens = tokenize(valdata, train_corpus, 35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f06d7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = np.stack(traindata[\"Tokens\"])\n",
    "trainY = np.array(traindata[\"Target\"])\n",
    "validX = np.stack(valdata[\"Tokens\"])\n",
    "validY = np.array(valdata[\"Target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "217170a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchtrain = TensorDataset(torch.from_numpy(trainX).to(torch.int64), torch.from_numpy(trainY).to(torch.int64))\n",
    "torchtval = TensorDataset(torch.from_numpy(validX).to(torch.int64), torch.from_numpy(validY).to(torch.int64))\n",
    "\n",
    "trainloader = DataLoader(torchtrain, shuffle=True, batch_size=16)\n",
    "validloader = DataLoader(torchtval, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56939a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 35])\n",
      "torch.Size([16, 1530])\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(train_corpus)\n",
    "embedding_dim = 32\n",
    "window_size = 4\n",
    "\n",
    "\n",
    "\n",
    "convs = nn.Sequential(\n",
    "    nn.Conv2d(1, 3, kernel_size=(2,2), padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.1),\n",
    "    nn.Conv2d(3, 5, kernel_size=(2,2), padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "    nn.Flatten()\n",
    ")\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "inputs, labels = next(dataiter)\n",
    "print(inputs.shape)\n",
    "labels = labels.to(torch.int64)\n",
    "lengths = 35 - (inputs == 0).sum(dim=1)\n",
    "\n",
    "embed = nn.Embedding(vocab_size, embedding_dim)\n",
    "# out = cnn(inputs)\n",
    "embeds = embed(inputs)\n",
    "\n",
    "pool = nn.MaxPool2d(kernel_size=(2,2))\n",
    "\n",
    "x = torch.unsqueeze(embeds, 1)\n",
    "\n",
    "x2 = convs(x)\n",
    "\n",
    "print(x2.shape)\n",
    "# embeds = nn.utils.rnn.pack_padded_sequence(embeds, list(lengths), batch_first=True, enforce_sorted=False)\n",
    "# print(embeds[:, None, :, :].shape)\n",
    "# embeds = embeds[:, None, :, :]\n",
    "# cnn(embeds)\n",
    "# inputs, labels = inputs.to(device), labels.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "900d7c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentCNN(nn.Module):\n",
    "    def __init__(self, voab_size, embedding_dim):\n",
    "        super(SentimentCNN, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(voab_size, embedding_dim)\n",
    "        self.out_dim = 1\n",
    "\n",
    "        self.convs = nn.Sequential(\n",
    "            nn.Conv2d(1, 3, kernel_size=(2,2), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(3, 5, kernel_size=(2,2), padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "    \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear = nn.Linear(1530, 4)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        batch_size = input.size(0)\n",
    "        embeds = self.embedding(input)\n",
    "        embeds = torch.unsqueeze(embeds, 1)\n",
    "        # embeds = nn.utils.rnn.pack_padded_sequence(embeds, list(lengths), batch_first=True, enforce_sorted=False)\n",
    "        out = self.convs(embeds)\n",
    "\n",
    "        # print(rnn_out)\n",
    "        # output_padded, output_lengths = pad_packed_sequence(rnn_out, batch_first=True)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "194639f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0213, -0.1923, -0.1165, -0.3064],\n",
      "        [ 0.0854, -0.1728, -0.0902, -0.2845],\n",
      "        [ 0.0832, -0.1728, -0.0454, -0.2144],\n",
      "        [-0.0073, -0.2488, -0.0659, -0.2373],\n",
      "        [ 0.1092, -0.2640, -0.0209, -0.2556],\n",
      "        [ 0.0509, -0.2021, -0.0179, -0.1298],\n",
      "        [-0.0109, -0.1734, -0.0786, -0.2712],\n",
      "        [ 0.0033, -0.2159, -0.0797, -0.1822],\n",
      "        [ 0.0581, -0.1984, -0.0376, -0.1642],\n",
      "        [ 0.1027, -0.1448,  0.0589, -0.2996],\n",
      "        [ 0.1074, -0.1741, -0.1590, -0.2512],\n",
      "        [ 0.0132, -0.2135, -0.0807, -0.1726],\n",
      "        [ 0.0418, -0.1721,  0.0264, -0.1918],\n",
      "        [ 0.0373, -0.2345, -0.0210, -0.3021],\n",
      "        [ 0.0737, -0.1853, -0.0901, -0.2719],\n",
      "        [ 0.0449, -0.1761, -0.0117, -0.1786]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "lr=0.0001\n",
    "no_layers = 3\n",
    "vocab_size = len(train_corpus)\n",
    "embedding_dim = 32\n",
    "hidden_dim = 128\n",
    "\n",
    "model = SentimentCNN(vocab_size, embedding_dim)\n",
    "model.to(device)\n",
    "\n",
    "#moving to gpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer.step()\n",
    "\n",
    "inputs, labels = next(dataiter)\n",
    "labels = labels.to(torch.int64)\n",
    "inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "output = model(inputs)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "279c2c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.002\n",
    "no_layers = 2\n",
    "vocab_size = len(train_corpus)\n",
    "\n",
    "model = SentimentCNN(vocab_size, embedding_dim)\n",
    "\n",
    "#moving to gpu\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# device = \"cpu\"\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# function to predict accuracy\n",
    "def acc(pred,label):\n",
    "    pred = torch.round(pred.squeeze())\n",
    "    return torch.sum(pred == label.squeeze()).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c622c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "valid_loss_min = np.Inf\n",
    "batch_size = 16\n",
    "\n",
    "epoch_tr_loss, epoch_vl_loss = [],[]\n",
    "epoch_tr_acc, epoch_vl_acc = [],[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = 0.0\n",
    "    corr = 0\n",
    "    tot = 0\n",
    "\n",
    "    corrval = 0\n",
    "    totval = 0\n",
    "    model.train()\n",
    "    # initialize hidden state \n",
    "    for inputs, labels in trainloader:\n",
    "        labels = labels.to(torch.int64)\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        model.zero_grad()\n",
    "\n",
    "        output = model(inputs)\n",
    "        # calculate the loss and perform backprop\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        train_losses.append(loss.item())\n",
    "        optimizer.step()\n",
    "        preds = torch.argmax(output, 1)\n",
    "        corr += (preds == labels).sum().item()\n",
    "        tot += 16\n",
    "\n",
    "    for val_inputs, val_labels in validloader:\n",
    "        val_labels = val_labels.to(torch.int64)\n",
    "        val_inputs, val_labels = val_inputs.to(device), val_labels.to(device)\n",
    "\n",
    "        val_output = model(val_inputs)\n",
    "        val_loss = criterion(val_output, val_labels)\n",
    "        val_losses.append(val_loss.item())\n",
    "        # calculate the loss and perform backprop\n",
    "        val_preds = torch.argmax(val_output, 1)\n",
    "        corrval += (val_preds == val_labels).sum().item()\n",
    "        totval += 16\n",
    "\n",
    "    epoch_train_loss = np.mean(train_losses)\n",
    "    epoch_val_loss = np.mean(val_losses)\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    print(f'train_loss : {epoch_train_loss}')\n",
    "    print(f'val_loss: {epoch_val_loss}')\n",
    "    print(f'train_accuracy : {corr/tot*100}')\n",
    "    print(f\"valid accuracy: {corrval/totval*100}\")\n",
    "    \n",
    "    epoch_tr_loss.append(epoch_train_loss)\n",
    "    epoch_vl_loss.append(epoch_val_loss)\n",
    "\n",
    "    epoch_tr_acc.append(corr/tot*100)\n",
    "    epoch_vl_acc.append(corrval/totval*100)\n",
    "\n",
    "    if epoch_val_loss <= valid_loss_min:\n",
    "        torch.save(model.state_dict(), 'working/CNN/state_dict.pt')\n",
    "        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,epoch_val_loss))\n",
    "        valid_loss_min = epoch_val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b70006be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andy8\\anaconda3\\envs\\stock_trade\\lib\\site-packages\\pandas\\core\\ops\\array_ops.py:75: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x.ravel(), y, op)\n",
      "C:\\Users\\andy8\\AppData\\Local\\Temp\\ipykernel_9008\\3237871160.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Tokens'] = df[\"Tokens\"].apply(pad)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuacy is: 0.9364754098360656\n"
     ]
    }
   ],
   "source": [
    "testdf = pd.read_csv(\"twitter_validation.csv\", header = None)\n",
    "testdf = testdf.drop([0, 1], axis = 1)\n",
    "dtestdff = testdf.applymap(str)\n",
    "testdf.columns = [\"Sentiment\", \"Text\"]\n",
    "testdf[\"Target\"] = testdf[\"Sentiment\"].map({\"Negative\" : 0, \"Positive\" : 1, \"Neutral\" : 2, \"Irrelevant\" : 3})\n",
    "\n",
    "df_processed_test = process_data(testdf)\n",
    "\n",
    "max_len = 35\n",
    "testdata, testlens = tokenize(df_processed_test, train_corpus, 35)\n",
    "\n",
    "testX = np.stack(testdata[\"Tokens\"])\n",
    "testY = np.array(testdata[\"Target\"])\n",
    "torchtest = TensorDataset(torch.from_numpy(testX).to(torch.int64), torch.from_numpy(testY).to(torch.int64))\n",
    "\n",
    "testloader = DataLoader(torchtest, shuffle=True, batch_size=16)\n",
    "\n",
    "corrval = 0\n",
    "totval = 0\n",
    "\n",
    "bestmodel = SentimentCNN(vocab_size, embedding_dim)\n",
    "bestmodel.load_state_dict(torch.load('working/CNN/state_dict.pt'))\n",
    "bestmodel.to(device)\n",
    "\n",
    "for inputs, labels in testloader:\n",
    "    labels = labels.to(torch.int64)\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "    output = bestmodel(inputs)\n",
    "    # calculate the loss and perform backprop\n",
    "    preds = torch.argmax(output, 1)\n",
    "    corrval += (preds == labels).sum().item()\n",
    "    totval += 16\n",
    "\n",
    "print(f\"The test accuacy is: {corrval/totval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8281f0bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2754bde8910>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_tr_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8279553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence, model, tweet_corpus, max_len):\n",
    "    sentence = sentence.lower()\n",
    "    words = sentence.split(\" \")\n",
    "    corpus_dict = corpora.Dictionary([tweet_corpus]).token2id\n",
    "    tokens = [corpus_dict[x] for x in words if x in corpus_dict]\n",
    "    if len(tokens) <= 1:\n",
    "        print(\"No Valid Strings!\")\n",
    "        return None\n",
    "    else:\n",
    "        tokens = np.array(tokens)\n",
    "\n",
    "    if len(tokens) < max_len:\n",
    "        tokens = np.append(tokens, [0]*(max_len - len(tokens)))\n",
    "        tokens = tokens[0:max_len]\n",
    "    \n",
    "    tokens = torch.LongTensor(tokens[None, :])\n",
    "    tokens = tokens.to(device)\n",
    "    output = model(tokens)\n",
    "    preds = torch.argmax(output, 1)\n",
    "    return preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1], device='cuda:0')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"I like cheese\", model, train_corpus, 35)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock_trade",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
